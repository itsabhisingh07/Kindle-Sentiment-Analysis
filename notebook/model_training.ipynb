{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0aee4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\itsab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a3a4c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('../dataset/all_kindle_review .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a8bf36bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ffffaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extracting noly 2 columns , One for Input and other for Output\n",
    "data=data[['reviewText','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ee49914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "34e9674c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Checking missing value\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9e41673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Cheking unique value for rating columns\n",
    "data['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e4e88a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For preprocessing and Cleaning\n",
    "data['rating']=data['rating'].apply(lambda x:0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "99308dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "11995    1\n",
       "11996    1\n",
       "11997    1\n",
       "11998    0\n",
       "11999    1\n",
       "Name: rating, Length: 12000, dtype: int64>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##To check the output column value\n",
    "data['rating'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "75828871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Checking if the dataset is balanced or not\n",
    "data['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7aa3d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## on Input dataset\n",
    "data['reviewText']=data['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d2ebb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cleaning\n",
    "## for special character\n",
    "data['reviewText']=data['reviewText'].apply(lambda x:re.sub('[^a-z A-Z 0-9]+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b85cd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For stopwords\n",
    "data['reviewText']=data['reviewText'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7da132c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing urls\n",
    "data['reviewText']=data['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&/~+#-]*[\\w.,@?^=%&/~+#-])?','',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "adcceef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove html tags\n",
    "data['reviewText']=data['reviewText'].apply(lambda x: BeautifulSoup(x,'lxml').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "874b18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing all extra spaces\n",
    "data['reviewText']=data['reviewText'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1f3fc19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short hes nothing mess man hau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sitti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start saying first four books wasnt expect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carries pocketbooks inst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library pleased find price right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may short hes nothing mess man hau...       1\n",
       "1  great short read didnt want put read one sitti...       1\n",
       "2  ill start saying first four books wasnt expect...       1\n",
       "3  aggie angela lansbury carries pocketbooks inst...       1\n",
       "4  expect type book library pleased find price right       1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eb40b704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\itsab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7b83cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "data['reviewText']=data['reviewText'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e844c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train - Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['reviewText'],data['rating'],test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "71908e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For BOW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow=CountVectorizer()\n",
    "X_train_bow=bow.fit_transform(X_train).toarray()\n",
    "X_test_bow=bow.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "34fcec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train_tfidf=tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf=tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b58ccb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "nb_model_bow=RandomForestClassifier().fit(X_train_bow,y_train)\n",
    "nb_model_tfidf=RandomForestClassifier().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c06fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8c7d9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow=nb_model_bow.predict(X_test_bow)\n",
    "y_pred_tfidf=nb_model_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "11cfb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "78043200",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Avg Woed2Vec\n",
    "X_train_tokens = [gensim.utils.simple_preprocess(text) for text in X_train]\n",
    "X_test_tokens = [gensim.utils.simple_preprocess(text) for text in X_test]\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train_tokens, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "def avg_word2vec(doc_tokens):\n",
    "   \n",
    "    words_in_vocab = [word for word in doc_tokens if word in w2v_model.wv.index_to_key]\n",
    "    \n",
    "    if len(words_in_vocab) > 0:\n",
    "        return np.mean(w2v_model.wv[words_in_vocab], axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "\n",
    "X_train_w2v = np.array([avg_word2vec(tokens) for tokens in X_train_tokens])\n",
    "X_test_w2v = np.array([avg_word2vec(tokens) for tokens in X_test_tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "910a3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_w2v = RandomForestClassifier()\n",
    "rf_w2v.fit(X_train_w2v, y_train)\n",
    "rf_w2v.fit(X_train_w2v, y_train)\n",
    "y_pred_w2v = rf_w2v.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d43163aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW accuracy:  0.8083333333333333\n",
      "tfidf accuracy:  0.7966666666666666\n",
      "AvgWord2Vec Accuracy: 0.75875\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW accuracy: \",accuracy_score(y_test,y_pred_bow))\n",
    "print(\"tfidf accuracy: \",accuracy_score(y_test,y_pred_tfidf))\n",
    "print(\"AvgWord2Vec Accuracy:\", accuracy_score(y_test, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0fe2b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Matrix: \n",
      " [[ 394  392]\n",
      " [  68 1546]]\n",
      "tfidf Matrix: \n",
      " [[ 367  419]\n",
      " [  69 1545]]\n",
      "Average Word2Vec:\n",
      " [[ 435  351]\n",
      " [ 228 1386]]\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW Matrix: \\n\",confusion_matrix(y_test,y_pred_bow))\n",
    "print(\"tfidf Matrix: \\n\",confusion_matrix(y_test,y_pred_tfidf))\n",
    "print(\"Average Word2Vec:\\n\",confusion_matrix(y_test, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9e18ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(tfidf, open('vectorizer.pkl', 'wb'))\n",
    "pickle.dump(nb_model_tfidf, open('model.pkl', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
